# -*- coding: utf-8 -*-
"""House Prices.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ievAMpv0PbjAEeL2Pe7elWn9vdvs5TnK

1. Датасет House Prices Kaggle со страницы конкурса<br>
    (https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data)
    2. Загрузите в pandas DataFrame под названием df.
    3. Выполните предварительную обработку данных, выполнив следующие шаги:
    a. Определите и обработайте отсутствующие значения в датасете.
    Определите, в каких столбцах есть отсутствующие значения, и решите, как их обработать
    (например, заполнить средним, медианой или модой, или отбросить столбцы/строки с
    существенными отсутствующими значениями).
    b. Проверьте и обработайте любые дублирующиеся строки в датасете.
    c. Проанализируйте типы данных в каждом столбце и при необходимости преобразуйте их
    (например, из объектных в числовые типы).
    4. Проведите разведочный анализ данных (EDA), ответив на следующие вопросы:
    a. Каково распределение целевой переменной 'SalePrice'?
    Есть ли какие-либо выбросы?
    b. Исследуйте взаимосвязи между целевой переменной и другими характеристиками. Есть ли сильные корреляции?
    c. Исследуйте распределение и взаимосвязи других важных характеристик, таких как 'OverallQual',
    'GrLivArea', 'GarageCars' и т.д.
    d. Визуализируйте данные, используя соответствующие графики (например, гистограммы, диаграммы рассеяния,
    квадратные диаграммы), чтобы получить представление о датасете.
    5. Выполните проектирование признаков путем реализации следующих преобразований:
    a. Работайте с категориальными переменными, применяя one-hot encoding или label encoding,
    в зависимости от характера переменной.
    b. При необходимости создайте новые характеристики, такие как общая площадь или возраст
    объекта недвижимости, путем объединения существующих характеристик.
    6. Сохраните очищенный и преобразованный набор данных в новый CSV-файл
    под названием 'cleaned_house_prices.csv'.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

#Подгружаем данные

df = pd.read_csv('train_data.csv')

# Выводим датафрейм
df

# Посмотрим размеры: строки / столбцы
df.shape

# Выведем названия всех столбцов
df.columns

# Генерируем описательную статистику
df.describe()

# Выведем имеющуюся информацию о датафрейме
df.info()

# Посмотрим количество пропущенных значений для каждого столбца
df.isnull().sum()

# Визуализируем
total = df.isnull().sum().sort_values(ascending=False)
percent = (df.isnull().sum() / df.isnull().count()).sort_values(ascending=False)
missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])

# Гистограмма
percent_data = percent.head(20)
percent_data.plot(kind="bar", figsize = (8,6), fontsize = 10)
plt.xlabel("Столбцы", fontsize = 20)
plt.ylabel("Count", fontsize = 20)
plt.title("Общее количество недостающих значений  (%)", fontsize = 20)

# Неполностью заполненные столбцы:

# 3   LotFrontage    1201 non-null   float64 погонные футы улицы, соединенной с участком.
# 6   Alley          91 non-null     object  тип подъезда к дороге
# 25  MasVnrType     588 non-null    object  тип каменной облицовки.
# 26  MasVnrArea     1452 non-null   float64 площадь каменного шпона в квадратных футах.
# 30  BsmtQual       1423 non-null   object  высота подвала.
# 31  BsmtCond       1423 non-null   object  общее состояние подвала
# 32  BsmtExposure   1422 non-null   object  стены подвала на уровне сада или выходного этажа.
# 33  BsmtFinType1   1423 non-null   object  качество готовой площади подвала.
# 35  BsmtFinType2   1422 non-null   object  качество второй готовой площади (если имеется).
# 57  FireplaceQu    770 non-null    object  качество камина
# 58  GarageType     1379 non-null   object  расположение гаража
# 59  GarageYrBlt    1379 non-null   float64 год постройки гаража.
# 60  GarageFinish   1379 non-null   object  внутренняя отделка гаража.
# 63  GarageQual     1379 non-null   object  внутренняя отделка гаража.
# 64  GarageCond     1379 non-null   object  состояние гаража
# 72  PoolQC         7 non-null      object  качество бассейна
# 73  Fence          281 non-null    object  качество забора
# 74  MiscFeature    54 non-null     object  разные функции, не вошедшие в другие

# Заполним пропущенные значения указанных столбцов (характеристики подвала и гаража) наиболее частыми значениями (модами)

columns_to_mode = ['BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond']

for column in columns_to_mode:
    mode_rating = df[column].mode()
    df[column] = df[column].fillna(mode_rating[0])

# Пропущенные значения столбцов 'LotFrontage', 'MasVnrArea' заполненим средними значениями

columns_to_mean = ['LotFrontage', 'MasVnrArea']

for column in columns_to_mean:
    mean_rating = df[column].mean()
    print(mean_rating)
    df[column] = df[column].fillna(mean_rating)

# Удалим неинформативные столбцы

columns_to_remove = ['Alley', 'MasVnrType', 'BsmtExposure', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']

df = df.drop(columns=columns_to_remove)

# Подсчет дубликатов в df
duplicates_by_columns = df.duplicated().sum()

# Вывод результата
print(f"Количество дубликатов: {duplicates_by_columns}")

# Подсчет дубликатов с учетом указанных колонок
duplicates_by_columns = df.duplicated(['Id']).sum()

# Вывод результата
print(f"Количество дубликатов: {duplicates_by_columns}")

# Проверим все значения в 'object' столбцах на тип данных
for col in df.columns:
    if df[col].dtype == 'object':
        unique_values = df[col].unique()
        print(f"Уникальные значения в столбце '{col}': {unique_values}")

"""! т.к. все значения объектных типов - строки, нет необходимости в преобразовании"""

# Посмотрим на нашу целевую переменную SalePrice

df['SalePrice'].describe()

"""Стандартное отклонение слишком велико, большая разница между минимальным значением и 25-м процентилем, разница между 75-м процентилем и максимумом больше, чем 25-й процентиль и максимум, полагаем, что цена дома существенно отклоняется от нормального распределения.


"""

# Построим гистограмму, чтобы отобразить распределение

plt.figure(figsize=(8, 6))
sns.histplot(df['SalePrice'], kde=True)
plt.title('Гистограмма SalePrice')
plt.xlabel('Цена')
plt.ylabel('Частота данной цены')
plt.show()

"""график подтверждает, что распределение не является нормальным"""

# Рассчитываем асимметрию и эксцесс для более точной оценки
print("Ассиметрия: %f" % df['SalePrice'].skew())
print("Эксцесс: %f" % df['SalePrice'].kurt())

"""Ассиметрия: 1.88, что говорит о смещении распределения.
Эксцесс равный 6.54, что также указывает на нестандартное распределение.

Применение логарифмического преобразования к целевой переменной позволит сделать распределение более близким к нормальному
"""

# Посмотрим на выбросы при помощи графика "Ящик с усами"
plt.figure(figsize=(8, 6))
sns.boxplot(data=df, y='SalePrice')
plt.title('SalePrice')
plt.ylabel('Цена')
plt.show()

# Применим логарифмическое преобразование

fig = plt.figure(figsize = (14,8))

# Распределение на необработанных данных
fig.add_subplot(1,2,1)
res = stats.probplot(df['SalePrice'], plot=plt)

# Распределение с логарифмическим преобразованием 'SalePrice'
fig.add_subplot(1,2,2)
res = stats.probplot(np.log1p(df['SalePrice']), plot=plt)

#  Посмотрим, с какими признаками коррелирует целевая переменная SalePrice, но прежде чем выведем матрицу корреляции
#  предварительно закодируем категориальные признаки в числовые значения, методом One-Hot Encoding

df_encoded = pd.get_dummies(df)

# Вычисление матрицы корреляции

corrmat = df_encoded.corr()

# Визуализация матрицы корреляции с использованием seaborn

plt.figure(figsize=(12, 9))
sns.heatmap(corrmat, vmax=.8, square=True)
plt.show()

# Выведем матрицу по интересующим нас признакам
features = ['OverallQual', 'GrLivArea', 'GarageCars', 'SalePrice']

# Вычислим коэффициенты корреляции только для выбранных признаков
cm = np.corrcoef(df_encoded[features].values.T)

# Визуализация усеченной матрицы корреляции
sns.set(font_scale=1.25)
plt.figure(figsize=(8, 6))
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=features, xticklabels=features)
plt.show()

# Проверим эти признаки на наличие выбросов:
fig, ax = plt.subplots()
ax.scatter(x = df['OverallQual'], y = df['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('OverallQual', fontsize=13)
plt.show()

fig, ax = plt.subplots()
ax.scatter(x = df['GrLivArea'], y = df['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('GrLivArea', fontsize=13)
plt.show()

fig, ax = plt.subplots()
ax.scatter(x = df['GarageCars'], y = df['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('GarageCars', fontsize=13)
plt.show()

# Выбросы незначительны, но удаление выделяющихся значений, может улучшить результат

df = df.drop(df[(df['OverallQual'] > 9) & (df['SalePrice'] < 350000)].index)
df = df.drop(df[(df['GrLivArea'] > 4000) & (df['SalePrice'] < 500000)].index)
df = df.drop(df[(df['GarageCars'] > 3100) & (df['SalePrice'] < 500000)].index)

# Применение кодирования One-Hot:

# Проверим уникальные значения в столбце 'Utilities'
unique_utilities = df['Utilities'].unique()

# Вывод уникальных значений
print(unique_utilities)

# Применение кодирования One-Hot
encoded_utilities = pd.get_dummies(df['Utilities'], prefix='Utility')

# Объединение закодированных столбцов с исходным DataFrame
final_df = pd.concat([df, encoded_utilities], axis=1)

# Выбор исходного столбца 'Utilities' и закодированных столбцов
selected_columns = pd.concat([df['Utilities'], encoded_utilities], axis=1)

# Вывод выбранных столбцов
print(selected_columns)

# Сохраняем очищенные и преобразованные данные в новый CSV-файл под названием 'cleaned_house_prices.csv'

final_df.to_csv('cleaned_house_prices.csv', index=False)

# Вывод сообщения об успешном сохранении
print('Данные успешно сохранены в файл "cleaned_house_prices.csv"')